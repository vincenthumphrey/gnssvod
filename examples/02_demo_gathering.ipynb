{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a267e0f9-b4b8-45ab-9d70-d7045571d9e6",
   "metadata": {},
   "source": [
    "# Merging processed data\n",
    "This notebook relies on the data from the previous notebook (but there is no need to run the previous notebook for this one to work however)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fedbcaf-dde3-436d-bf2d-5cc0b24129a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnssvod as gv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da3daa-f534-4957-8d4c-09d7ec50d67b",
   "metadata": {},
   "source": [
    "## Merge\n",
    "In the previous notebook, we processed raw RINEX observation files individually for each receiver and saved the results in corresponding NetCDF files.\n",
    "\n",
    "In the case of a GNSS-VOD set up, receivers are analysed as pairs. One receiver lies above the forest canopy and provides a clear-sky reference, and the other one lies below the canopy and measures the forest attenuation.\n",
    "\n",
    "Here we merge the data from these two receivers before making any plots. We also save the merged data in chunks that are always the same (for example we save them in daily chunks). This makes it easier to manipulate data and avoids relying on the temporal chunks with which data was initially logged (here data was logged in hourly log files that span from xx:07 too xx+1:06).\n",
    "\n",
    "### gv.gather_stations()\n",
    "This function will do several things\n",
    "- It will read processed observation files that were saved in NetCDF format (output of \"preprocess\").\n",
    "- It will combine data from the various receivers/stations according to user-specified pairing rules.\n",
    "- It will only process data belonging to the requested time interval.\n",
    "- It will save paired data in temporal chunks specified by the time interval.\n",
    "- If requested, it will also return the paired data as an object\n",
    "\n",
    "#### Specifying input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2e95bb-d5a9-4887-9206-aec3223f8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's indicate where to find the data for each receiver\n",
    "pattern={'Dav2_Twr':'data_RINEX2.11/Dav2_Twr/nc/*.nc',\n",
    "         'Dav1_Grnd':'data_RINEX2.11/Dav1_Grnd/nc/*.nc'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064dc425-b818-4ec8-b893-e5387ea2c0fa",
   "metadata": {},
   "source": [
    "#### Specifying time interval\n",
    "Then we need to define the temporal interval and the temporal chunks we will want for the output data\n",
    "                                                                             \n",
    "Here we decide to process all data from '28-04-2021' to '29-04-2021', meaning 2 days, starting at '28-04-2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7bcab7-266b-4e47-b016-bb66f5b6a87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntervalIndex([[2021-04-28 00:00:00, 2021-04-29 00:00:00), [2021-04-29 00:00:00, 2021-04-30 00:00:00)], dtype='interval[datetime64[ns], left]')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startday = pd.to_datetime('28-04-2021',format='%d-%m-%Y')\n",
    "timeintervals=pd.interval_range(start=startday, periods=2, freq='D', closed='left')\n",
    "timeintervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716a18c-aec0-4f30-b143-3ccd6cf73218",
   "metadata": {},
   "source": [
    "Using the timeintervals above will save the results in chunks of 1 day. If we wanted the results in hourly chunks, we could have written instead:\n",
    "\n",
    "`timeintervals=pd.interval_range(start=startday, periods=48, freq='H', closed='left')`\n",
    "\n",
    "Now the only thing left is to define how to combine the stations, using the same dictionary keys as in 'pattern'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56232ec2-f8e8-4421-ad97-6400919e88a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Epochs from files\n",
      "----- Processing Dav\n",
      "-- Processing interval [2021-04-28 00:00:00, 2021-04-29 00:00:00)\n",
      "Found 3 file(s) for Dav2_Twr\n",
      "Reading\n",
      "Found 3 file(s) for Dav1_Grnd\n",
      "Reading\n",
      "Concatenating stations\n",
      "-- Processing interval [2021-04-29 00:00:00, 2021-04-30 00:00:00)\n",
      "Found 4 file(s) for Dav2_Twr\n",
      "Reading\n",
      "Found 4 file(s) for Dav1_Grnd\n",
      "Reading\n",
      "Concatenating stations\n"
     ]
    }
   ],
   "source": [
    "# define how to make pairs, always give reference station first, matching the dictionary keys of 'pattern'\n",
    "pairings={'Dav':('Dav2_Twr','Dav1_Grnd')}\n",
    "\n",
    "# run function\n",
    "out = gv.gather_stations(pattern,pairings,timeintervals,outputresult=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc79c1-19e9-44d3-9960-d4b71b8bf251",
   "metadata": {},
   "source": [
    "If outputresult was set to 'True' (default is 'False'), the returned result is of the form\n",
    "\n",
    "out = dict(key=pd.DataFrame,\n",
    "<br>&emsp;&emsp;&emsp;&emsp;&emsp;key=pd.DataFrame)\n",
    "\n",
    "In our case, something like:\n",
    "\n",
    "out = {'Dav':pd.DataFrame}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fad3763-17c3-402d-a1a0-505388754fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dav':                                           S1         S2         S7  \\\n",
       " Station   Epoch               SV                                     \n",
       " Dav2_Twr  2021-04-28 21:07:00 C06  38.000000  38.000000  31.000000   \n",
       "                               C09  41.000000  41.000000  36.000000   \n",
       "                               C11  43.428571  43.428571  41.000000   \n",
       "                               C14  45.000000  45.000000  42.285714   \n",
       "                               C16  38.000000  38.000000  33.000000   \n",
       " ...                                      ...        ...        ...   \n",
       " Dav1_Grnd 2021-04-29 03:07:00 R16  32.200000  31.700000        NaN   \n",
       "                               R23  27.700000        NaN        NaN   \n",
       "                               S23  36.000000        NaN        NaN   \n",
       "                               S27  29.100000        NaN        NaN   \n",
       "                               S36  35.000000        NaN        NaN   \n",
       " \n",
       "                                       Azimuth  Elevation  \n",
       " Station   Epoch               SV                          \n",
       " Dav2_Twr  2021-04-28 21:07:00 C06   36.614495  10.132689  \n",
       "                               C09   49.034472  32.742503  \n",
       "                               C11  177.234549  35.079888  \n",
       "                               C14  -96.373353  76.785189  \n",
       "                               C16   38.266603  15.249211  \n",
       " ...                                       ...        ...  \n",
       " Dav1_Grnd 2021-04-29 03:07:00 R16 -173.516286  68.863646  \n",
       "                               R23         NaN        NaN  \n",
       "                               S23         NaN        NaN  \n",
       "                               S27         NaN        NaN  \n",
       "                               S36         NaN        NaN  \n",
       " \n",
       " [89336 rows x 5 columns]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07f5f97-80f1-4f32-9358-2142a36fb755",
   "metadata": {},
   "source": [
    "We can see that a new MultiIndex level named 'Station' has been added. Data from both stations now appear in the same table, with aligned Epochs and SV numbers.\n",
    "\n",
    "#### Specifying output destination\n",
    "Instead of just returning the result as an output of the function, we can specify where to save it instead. Again it may also be useful to get rid of some variables that are not useful in order to reduce file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351245e9-b575-4433-a78f-fc3e08130672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Epochs from files\n",
      "----- Processing Dav\n",
      "-- Processing interval [2021-04-28 00:00:00, 2021-04-29 00:00:00)\n",
      "Found 3 file(s) for Dav2_Twr\n",
      "Reading\n",
      "Found 3 file(s) for Dav1_Grnd\n",
      "Reading\n",
      "Concatenating stations\n",
      "Saving result in data_RINEX2.11/Dav_paired/\n",
      "Saved 43172 observations in Dav_20210428000000_20210429000000.nc\n",
      "-- Processing interval [2021-04-29 00:00:00, 2021-04-30 00:00:00)\n",
      "Found 4 file(s) for Dav2_Twr\n",
      "Reading\n",
      "Found 4 file(s) for Dav1_Grnd\n",
      "Reading\n",
      "Concatenating stations\n",
      "Saving result in data_RINEX2.11/Dav_paired/\n",
      "Saved 46164 observations in Dav_20210429000000_20210430000000.nc\n"
     ]
    }
   ],
   "source": [
    "# define where to save output data, matching the dictionary keys in 'pairings'\n",
    "outputdir = {'Dav':'data_RINEX2.11/Dav_paired/'}\n",
    "# define which variables to keep\n",
    "keepvars = ['S*','Azimuth','Elevation']\n",
    "\n",
    "# run function\n",
    "out = gv.gather_stations(pattern,pairings,timeintervals,keepvars=keepvars,outputdir=outputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14ccda-7cde-4ece-a465-be4114a08d6a",
   "metadata": {},
   "source": [
    "As we asked, the results have been saved as daily files (even though the input files are hourly files). The file names are generated based on the key of the 'pairing' argument (here 'Dav') and the specified time intervals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnss_2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
